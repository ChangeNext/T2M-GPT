{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.chdir(\"/workspace\")\n",
    "import torch\n",
    "from torch.utils import data\n",
    "import numpy as np\n",
    "from os.path import join as pjoin\n",
    "import random\n",
    "import codecs as cs\n",
    "from tqdm import tqdm\n",
    "import utils.paramUtil as paramUtil\n",
    "from torch.utils.data._utils.collate import default_collate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def collate_fn(batch):\n",
    "    batch.sort(key=lambda x: x[3], reverse=True)\n",
    "    return default_collate(batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import easydict\n",
    "\n",
    "args = easydict.EasyDict({\n",
    "    'dataname': 't2m',\n",
    "    'batch_size': 128,\n",
    "    'fps': [20],\n",
    "    'seq_len': 64,\n",
    "    'total_iter': 100000,\n",
    "    'warm_up_iter': 1000,\n",
    "    'lr': 0.0001,\n",
    "    'lr_scheduler': [150000],\n",
    "    'gamma': 0.05,\n",
    "    'weight_decay': 1e-6,\n",
    "    'decay_option': 'all',\n",
    "    'optimizer': 'adamw',\n",
    "    'code_dim': 512,\n",
    "    'nb_code': 512,\n",
    "    'mu': 0.99,\n",
    "    'down_t': 2,\n",
    "    'stride_t': 2,\n",
    "    'width': 512,\n",
    "    'depth': 3,\n",
    "    'dilation_growth_rate': 3,\n",
    "    'output_emb_width': 512,\n",
    "    'vq_act': 'relu',\n",
    "    'block_size': 25,\n",
    "    'embed_dim_gpt': 1024,\n",
    "    'clip_dim': 512,\n",
    "    'num_layers': 9,\n",
    "    'n_head_gpt': 16,\n",
    "    'ff_rate': 4,\n",
    "    'drop_out_rate': 0.1,\n",
    "    'quantizer': 'ema_reset',\n",
    "    'quantbeta': 1.0,\n",
    "    'resume_pth': \"output_vqfinal/VQ-VAE/reset/net_last.pth\",\n",
    "    'resume_trans': None,\n",
    "    'out_dir': 'output_GPT_Final/',\n",
    "    'exp_name': 'exp_debug',\n",
    "    'vq_name': 'exp_debug',\n",
    "    'print_iter': 200,\n",
    "    'eval_iter': 10000,\n",
    "    'seed': 123,\n",
    "    'if_maxtest': False,\n",
    "    'pkeep': 0.5\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''For use of training text-2-motion generative model'''\n",
    "class Text2MotionDataset(data.Dataset):\n",
    "    def __init__(self, dataset_name, feat_bias = 5, unit_length = 4, codebook_size = 1024, tokenizer_name=None):\n",
    "        \n",
    "        self.max_length = 64\n",
    "        self.pointer = 0\n",
    "        self.dataset_name = dataset_name\n",
    "\n",
    "        self.unit_length = unit_length\n",
    "        # self.mot_start_idx = codebook_size\n",
    "        self.mot_end_idx = codebook_size\n",
    "        self.mot_pad_idx = codebook_size + 1\n",
    "        if dataset_name == 't2m':\n",
    "            self.data_root = './dataset/HumanML3D'\n",
    "            self.motion_dir = pjoin(self.data_root, 'new_joint_vecs')\n",
    "            self.text_dir = pjoin(self.data_root, 'texts')\n",
    "            self.joints_num = 22\n",
    "            radius = 4\n",
    "            fps = 20\n",
    "            self.max_motion_length = 26 if unit_length == 8 else 51\n",
    "            dim_pose = 263\n",
    "            kinematic_chain = paramUtil.t2m_kinematic_chain\n",
    "        elif dataset_name == 'kit':\n",
    "            self.data_root = './dataset/KIT-ML'\n",
    "            self.motion_dir = pjoin(self.data_root, 'new_joint_vecs')\n",
    "            self.text_dir = pjoin(self.data_root, 'texts')\n",
    "            self.joints_num = 21\n",
    "            radius = 240 * 8\n",
    "            fps = 12.5\n",
    "            dim_pose = 251\n",
    "            self.max_motion_length = 26 if unit_length == 8 else 51\n",
    "            kinematic_chain = paramUtil.kit_kinematic_chain\n",
    "\n",
    "        split_file = pjoin(self.data_root, 'train.txt')\n",
    "\n",
    "        id_list = []\n",
    "        with cs.open(split_file, 'r') as f:\n",
    "            for line in f.readlines():\n",
    "                id_list.append(line.strip())\n",
    "\n",
    "        new_name_list = []\n",
    "        data_dict = {}\n",
    "        for name in tqdm(id_list):\n",
    "            try:\n",
    "                #motion의 코드북 token\n",
    "                m_token_list = np.load(pjoin(self.data_root, tokenizer_name, '%s.npy'%name))\n",
    "                 # Read text\n",
    "                with cs.open(pjoin(self.text_dir, name + '.txt')) as f:\n",
    "                    text_data = []\n",
    "                    flag = False\n",
    "                    lines = f.readlines()\n",
    "\n",
    "                    for line in lines:\n",
    "                        try:\n",
    "                            text_dict = {}\n",
    "                            line_split = line.strip().split('#')\n",
    "                            caption = line_split[0]\n",
    "                            t_tokens = line_split[1].split(' ')\n",
    "                            f_tag = float(line_split[2])\n",
    "                            to_tag = float(line_split[3])\n",
    "                            f_tag = 0.0 if np.isnan(f_tag) else f_tag\n",
    "                            to_tag = 0.0 if np.isnan(to_tag) else to_tag\n",
    "                            \n",
    "                            # if caption == \"the man is doing push ups\":\n",
    "                            #     print(name)\n",
    "                            text_dict['caption'] = caption\n",
    "                            \n",
    "                            text_dict['tokens'] = t_tokens\n",
    "\n",
    "                            if f_tag == 0.0 and to_tag == 0.0:\n",
    "                                flag = True\n",
    "                                text_data.append(text_dict)\n",
    "                            else:\n",
    "                                m_token_list_new = [tokens[int(f_tag*fps/unit_length) : int(to_tag*fps/unit_length)] for tokens in m_token_list if int(f_tag*fps/unit_length) < int(to_tag*fps/unit_length)]\n",
    "                                \n",
    "                                if len(m_token_list_new) == 0:\n",
    "                                    continue\n",
    "                                new_name = '%s_%f_%f'%(name, f_tag, to_tag)\n",
    "\n",
    "                                data_dict[new_name] = {'m_token_list': m_token_list_new,\n",
    "                                                       'text':[text_dict]}\n",
    "                                new_name_list.append(new_name)\n",
    "\n",
    "                        except:\n",
    "                            pass\n",
    "                if flag:\n",
    "                    data_dict[name] = {'m_token_list': m_token_list,\n",
    "                                       'text':text_data}\n",
    "                    new_name_list.append(name)\n",
    "            except:\n",
    "                pass\n",
    "        self.data_dict = data_dict\n",
    "        self.name_list = new_name_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_dict)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        data = self.data_dict[self.name_list[item]]\n",
    "        m_token_list, text_list = data['m_token_list'], data['text']\n",
    "        m_tokens = random.choice(m_token_list)\n",
    "        text_data = random.choice(text_list)\n",
    "\n",
    "        caption= text_data['caption']\n",
    "        coin = np.random.choice([False, False, True])\n",
    "        if coin:\n",
    "            # drop one token at the head or tail\n",
    "            coin2 = np.random.choice([True, False])\n",
    "            if coin2:\n",
    "                m_tokens = m_tokens[:-1]\n",
    "            else:\n",
    "                m_tokens = m_tokens[1:]\n",
    "        m_tokens_len = m_tokens.shape[0]\n",
    "        \n",
    "        # print(np.ones((self.max_motion_length-1-m_tokens_len)))\n",
    "        # print(m_tokens, np.ones((1), dtype=int) * self.mot_end_idx)\n",
    "\n",
    "        #padding 작업\n",
    "        if m_tokens_len+1 < self.max_motion_length:\n",
    "            m_tokens = np.concatenate([m_tokens, np.ones((1), dtype=int) * self.mot_end_idx, np.ones((self.max_motion_length-1-m_tokens_len), dtype=int) * self.mot_pad_idx], axis=0)\n",
    "        else:\n",
    "            print(1)\n",
    "            m_tokens = np.concatenate([m_tokens, np.ones((1), dtype=int) * self.mot_end_idx], axis=0)\n",
    "        \n",
    "        return caption, m_tokens.reshape(-1), m_tokens_len\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23384/23384 [00:03<00:00, 7086.37it/s]\n"
     ]
    }
   ],
   "source": [
    "a = Text2MotionDataset(args.dataname, codebook_size = 512, tokenizer_name = args.vq_name, unit_length=args.down_t*2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caption : a man flaps his arms like a chicken while bending up and down.\n",
      "m_token : [ 13  13  13  13  13  13  18 494  84 112 447 447 447 447 184 488 447 447\n",
      " 178 150 178  94 237 150 339 112 490 339 237 417 214 132 132 316 132 132\n",
      " 132 132 132 132 132 316 447 447 447 112 447 447 447 512 513]\n",
      "49\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('a man flaps his arms like a chicken while bending up and down.',\n",
       " array([ 13,  13,  13,  13,  13,  13,  18, 494,  84, 112, 447, 447, 447,\n",
       "        447, 184, 488, 447, 447, 178, 150, 178,  94, 237, 150, 339, 112,\n",
       "        490, 339, 237, 417, 214, 132, 132, 316, 132, 132, 132, 132, 132,\n",
       "        132, 132, 316, 447, 447, 447, 112, 447, 447, 447, 512, 513]),\n",
       " 49)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.__getitem__(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
